
While using TKE services, you need to consider the service quota applied to TKE, CVM, and managed clusters.

## TKE Quota Limit

The default TKE quota for each user is as follows. If you want to increase the quota, [submit a ticket](https://console.intl.cloud.tencent.com/workorder/category) for application.
>!From October 21, 2019, the maximum node quota for a cluster has been adjusted to at least 5,000.
>

<table>
	<tr>
	<th>Item</th>
	<th>Default Value</th>
	<th>Where to Check</th>
	<th>Quota Increase Allowed or Not</th>
	</tr>
	<tr>
	<td>Clusters in a region</td>
	<td>5</td>
	<td rowspan=5><a href="https://console.cloud.tencent.com/tke2/overview">Bottom-right section of the TKE overview page</a></td>
	<td rowspan=5>Yes</td>
	</tr>
	<tr>
	<td>Nodes in a cluster</td>
	<td>5,000</td>
	</tr>
	<tr>
	<td>Image namespaces in a region</td>
	<td>10</td>
	</tr>
	<tr>
	<td>Image repositories in a region</td>
	<td>500</td>
	</tr>
	<tr>
	<td>Tags of an image</td>
	<td>100</td>
	</tr>
</table>

## CVM Quota Limit

CVM instances generated by TKE are subject to purchase limits. For more information, see [Purchase Limits](https://intl.cloud.tencent.com/document/product/213/2664). If you need more quotas than the default, [submit a ticket](https://console.intl.cloud.tencent.com/workorder/category) for application.

<table>
	<tr>
	<th>Item</th>
	<th>Default Value</th>
	<th>Where to Check</th>
	<th>Quota Increase Allowed or Not</th>
	</tr>
	<tr>
    <td>Pay-as-you-go CVM instances in an AZ</td>
	<td>30 or 60</td>
	<td><a href="https://console.cloud.tencent.com/cvm/overview">CVM Instances page - Resources in each region</a></td>
	<td>Yes</td>
	</tr>
</table>


## Cluster Configuration Limit
>? Cluster configuration limits the cluster size and cannot be modified currently.
>

| Item | IP Address Range | Affected Scope | Where to Check | Modification Allowed or Not |
| ----- | ----- | ---- | --------- | ---------- |
| VPC network - Subnet | Custom | Number of nodes that can be added to the subnet |	[VPC subnet list page for the cluster - Number of available IP addresses](https://console.cloud.tencent.com/vpc/subnet)	| <ul class="params"><li>No</li><li>You can use a new subnet</li></ul> |
| Container CIDR block |	Custom |	<ul class="params"><li>Maximum number of nodes per cluster</li><li>Maximum number of services per cluster</li><li>Maximum number of Pods per node</li></ul> |	Basic information page for the cluster - Container CIDR block | No |

<style>
	.params{margin-bottom:0px !important;}
</style>

## K8s Resource Quota Description
>? The following quotas are automatically applied from April 30, 2022 (UTC +8) and cannot be adjusted. **You can increase the resource quota by upgrading the cluster model**.
> To adjust your quota, [submit a ticket](https://console.intl.cloud.tencent.com/workorder/category) for application.
>
Run the following command to check the quota:
```
kubectl get resourcequota tke-default-quota -o yaml
```
To check the `tke-default-quota` object of a specified namespace, add `--namespace` to specify the namespace.

>? 
> - Other K8s resource limit means that the number of all K8s resources in the cluster except Pod, Node, and ConfigMap **cannot** exceed this value. For example, for an L100 cluster, the number of ClusterRole, Service, Endpoint, and other K8s resources **cannot** exceed 10,000.
- **CRD** refers to **the sum of all CRDs** in the cluster. If the number of some CRDs increases, the number of other CRDs will decrease.

| Cluster Model | Pods | ConfigMap | CRDs/Other K8s Resources | 
| ---------------- | ------------------- | ------------------------- | ------------------- |
| L5             | 600                 | 256                       | 1,250                 |
| L20             | 1,500                | 512                     | 2,500               |
|  L50            | 3,000                | 1,024                    | 5,000              |
|  L100           | 6,000                | 2,048                    |10,000                |
|  L200              | 15,000               | 4,096                   | 20,000               |
|  L500        | 30,000               | 6,144                     | 50,000               |
|  L1000            | 90,000               | 8,192                  | 100,000            |
|  L3000             | 150,000              | 10,240                     | 150,000              |
|  L5000             | 200,000              | 20,480                    | 200,000              |

### Namespace quota
By default, **each namespace has the same margin (margin = quota for the current cluster level - amount already used by the entire cluster). If you create resources in a namespace, the margin will decrease, and the amount available in other namespaces will decrease accordingly after a certain period of time.**

If you want to customize the allocation ratio, you can create a `tke-quota-config` ConfigMap under `kube-system` to specify the **margin** allocation ratio for each namespace. 

The following example sets the **margin** allocation ratio to `50%` for the `default` namespace, `40%` for the `kube-system` namespace, and `10%` for the rest of the namespaces. **If the sum of the set percentages exceeds `100%`, TKE considers the ratio invalid and will use the default allocation policy**.
```
apiVersion: v1
data:
  default: "50"
  kube-system: "40"
kind: ConfigMap
metadata:
  name: tke-quota-config
  namespace: kube-system
```
